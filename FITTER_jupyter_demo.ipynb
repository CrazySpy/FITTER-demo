{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "299cb6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# @software{dias2019fuzzy,\n",
    "#   author       = {Madson Luiz Dantas Dias},\n",
    "#   title        = {fuzzy-c-means: An implementation of Fuzzy $C$-means clustering algorithm.},\n",
    "#   month        = may,\n",
    "#   year         = 2019,\n",
    "#   publisher    = {Zenodo},\n",
    "#   doi          = {10.5281/zenodo.3066222},\n",
    "#   url          = {https://git.io/fuzzy-c-means}\n",
    "# }\n",
    "from fcmeans import FCM\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c0e5830",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ca8193",
   "metadata": {},
   "source": [
    "# Input data\n",
    "\n",
    "We still use the example in Figure 2. If the input data has a large column dimansion, some dimensional reducing techniques can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3d8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [['A', 'B'], \n",
    "            ['A', 'B', 'C'], \n",
    "            ['A', 'B', 'D'], \n",
    "            ['A', 'B', 'C', 'D'], \n",
    "            ['A', 'C', 'D'], \n",
    "            ['B', 'C'], \n",
    "            ['B', 'C', 'D'], \n",
    "            ['B', 'C', 'E'], \n",
    "            ['B', 'D'], \n",
    "            ['B', 'E'], \n",
    "            ['C', 'D']]\n",
    "# The conditional co-occurrence matrix\n",
    "CM = np.array([[  1, 4/5, 3/5, 3/5,   0], \n",
    "               [1/2,   1, 5/8, 1/2, 1/4], \n",
    "               [3/7, 5/7,   1, 4/7, 1/7], \n",
    "               [1/2, 2/3, 2/3,   1,   0], \n",
    "               [  0,   1, 1/2,   0,   1]])\n",
    "\n",
    "n_features = CM.shape[0]\n",
    "feature_index = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "735947cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_init = PCA(n_components='mle')\n",
    "# CM = pca_init.fit_transform(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea3e08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "print(CM.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c638033",
   "metadata": {},
   "source": [
    "# Step 1: Multi-granularity fuzzy clustering embedding  (Section IV. B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd295aa7",
   "metadata": {},
   "source": [
    "### Multi-granularity fuzzy clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb03991",
   "metadata": {},
   "source": [
    "The function below returns a clustering indicator matrix (Def.11) according to the parameter n_clusters for fuzzy c-means clustering (FCM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8ba7268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_indicator_matrix(X, n_clusters):\n",
    "    # Execute a fuzzy c-means clustering.\n",
    "    fcm = FCM(n_clusters=n_clusters)\n",
    "    fcm.fit(X)\n",
    "    \n",
    "    # Return the indicator matrix.\n",
    "    return fcm.u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb77ba6",
   "metadata": {},
   "source": [
    "Then, we execute the fuzzy clustering with different number of clusters, which we called multi-granularity. The indicator matrices are collected and concatenated horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e45edbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████▋                             | 1/3 [00:00<00:00, 116.50it/s]\n"
     ]
    }
   ],
   "source": [
    "max_clusters = n_features - 1\n",
    "\n",
    "def remove_small_clusters(indicator_matrix, n_clusters):\n",
    "    # Calculate the sum of u_ij.\n",
    "    membership_sum = np.sum(indicator_matrix, axis=0)\n",
    "    # Check whether is in SC.\n",
    "    is_small = membership_sum <= math.ceil(n_features / n_clusters)\n",
    "\n",
    "    return np.delete(indicator_matrix, is_small, axis=1), np.sum(is_small)\n",
    "\n",
    "alpha = 1\n",
    "small_count = 0\n",
    "indicator_matrices = []\n",
    "for n_clusters in tqdm(range(2, max_clusters + 1)):\n",
    "    # Line 5 in Algorithm 2.\n",
    "    indicator_matrix = calc_indicator_matrix(CM, n_clusters)\n",
    "    # Lines 6-7 in Algorithm 2.\n",
    "    indicator_matrix, sc = remove_small_clusters(indicator_matrix, n_clusters)\n",
    "    # Line 8 in Algorithm 2.\n",
    "    indicator_matrices.append(indicator_matrix)\n",
    "    \n",
    "    # Check the quit condition. Line 9-12 in Algorithm 2.\n",
    "    small_count += sc\n",
    "    if small_count >= math.ceil(n_clusters / alpha):\n",
    "        break\n",
    "\n",
    "# The variable is named IM in the paper.\n",
    "concated_indicator_matrix = np.hstack(indicator_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0229bdb",
   "metadata": {},
   "source": [
    "In this case, the concatenated indicator matrix (i.e., $IM$) is shown as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15274632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9268 0.0246]\n",
      " [0.8947 0.628 ]\n",
      " [0.9217 0.8759]\n",
      " [0.9402 0.6342]\n",
      " [0.0006 0.0001]]\n"
     ]
    }
   ],
   "source": [
    "print(concated_indicator_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c5a22",
   "metadata": {},
   "source": [
    "Each column of the $IM$ represents affiliation degree (or called membership degree) to a cluster. Each cluster can be regarded as a semantic aspect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a768ff7",
   "metadata": {},
   "source": [
    "### PCA\n",
    "Finally, we try to execute a PCA on the resulted $IM$. That's because the coupling relations are not only exist among features but also semantic aspects. The PCA with a full number of components can be regarded as a change of basis, and independent semantics are captured. Moreover, PCA can be utilized to reduce dimensionalities, further refine the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0b52b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_concated_indicator_matrix = concated_indicator_matrix - np.mean(concated_indicator_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a405af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA() # PCA(n_components=) for dimensional reducing.\n",
    "EM = pca.fit_transform(centered_concated_indicator_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b92ed4",
   "metadata": {},
   "source": [
    "The embeddings are listed as below. Each column can be treated as an independent but principle semantic aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d45ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.1407  0.4275]\n",
      " [-0.2489 -0.0344]\n",
      " [-0.4383 -0.1966]\n",
      " [-0.2863 -0.0078]\n",
      " [ 0.8328 -0.1887]]\n"
     ]
    }
   ],
   "source": [
    "print(EM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2c3d0",
   "metadata": {},
   "source": [
    "### Markov's inequality for dimensional reducing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f330786",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec61f8c",
   "metadata": {},
   "source": [
    "1. Calculate distancs to other columns.\n",
    "2. Calculate average distances to others.\n",
    "3. Remove the clusters whose $maximum\\_distances$ is less than $\\frac{1}{1-\\epsilon}*average\\_distances$ (Markov's inquality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b7934cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if EM.shape[1] <= 1:\n",
    "        break\n",
    "    \n",
    "    exit_flag = True\n",
    "    for i in range(EM.shape[1]):\n",
    "        embedding = EM[:, i]\n",
    "        embedding_minus = EM - embedding[:, np.newaxis]\n",
    "        # Calculate distances to other columns.\n",
    "        distances = np.sqrt(np.sum(np.square(embedding_minus), axis=0))\n",
    "\n",
    "        maximum_distance = np.max(distances)\n",
    "        average_distance = np.sum(distances) / (EM.shape[1] - 1)\n",
    "        # Markov's inequality for dimensional reducing\n",
    "        if maximum_distance < 1 / (1-eps)*average_distance:\n",
    "            EM = np.delete(EM, i, axis=1)\n",
    "            exit_flag = False\n",
    "            break\n",
    "    if exit_flag:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685971da",
   "metadata": {},
   "source": [
    "The final EM is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b4806f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4275]\n",
      " [-0.0344]\n",
      " [-0.1966]\n",
      " [-0.0078]\n",
      " [-0.1887]]\n"
     ]
    }
   ],
   "source": [
    "print(EM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8353d3c8",
   "metadata": {},
   "source": [
    "# Step 2: Sampling and interaction (Section III. B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cea2e9",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3f780",
   "metadata": {},
   "source": [
    "Each sample has 3 patterns. The parameter $\\mu$ (Def. 5) is set to 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "003f673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_patterns = patterns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63e7f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 2\n",
    "mu = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b58faaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Def.2\n",
    "def calc_info(sample):\n",
    "    numerator_feature = set()\n",
    "    for p in sample:\n",
    "        for f in p:\n",
    "            numerator_feature.add(f)\n",
    "    \n",
    "    return len(numerator_feature) / n_features\n",
    "\n",
    "# Def.3\n",
    "def calc_local_info(sample):\n",
    "    return calc_info(sample)\n",
    "    \n",
    "# Def.4\n",
    "def calc_global_info(sample, history_samples):\n",
    "    return calc_info(sample + history_samples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "028eb550",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_samples = []\n",
    "def sample(candidate_patterns, sample_size=2, mu=0.5, verbose=True):\n",
    "    sample = []\n",
    "    if len(candidate_patterns) <= sample_size:\n",
    "        sample = candidate_patterns.copy()\n",
    "        candidate_patterns.clear()\n",
    "        return sample\n",
    "    \n",
    "    while len(sample) < sample_size:\n",
    "        best_info = 0\n",
    "        for idx, pattern in enumerate(candidate_patterns):\n",
    "            local_info = calc_local_info(sample + pattern)\n",
    "            global_info = calc_global_info(sample + pattern, history_samples)\n",
    "            info = mu * local_info + (1 - mu) * global_info\n",
    "            if verbose:\n",
    "                print(\"pattern: \", pattern, \", local info = %.3f, global info = %.3f, info = %.3f\" % (local_info, global_info, info))\n",
    "            if info > best_info:\n",
    "                best_info = info\n",
    "                best_pattern = pattern\n",
    "\n",
    "        sample.append(best_pattern)\n",
    "        history_samples.append(best_pattern)\n",
    "        candidate_patterns.remove(best_pattern)\n",
    "        if verbose:\n",
    "            print(\"-> pattern: \", best_pattern, \" is sampled!\")\n",
    "            print(\"-\"*80)\n",
    "        \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8c9e03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern:  ['A', 'B'] , local info = 0.400, global info = 0.400, info = 0.400\n",
      "pattern:  ['A', 'B', 'C'] , local info = 0.600, global info = 0.600, info = 0.600\n",
      "pattern:  ['A', 'B', 'D'] , local info = 0.600, global info = 0.600, info = 0.600\n",
      "pattern:  ['A', 'B', 'C', 'D'] , local info = 0.800, global info = 0.800, info = 0.800\n",
      "pattern:  ['A', 'C', 'D'] , local info = 0.600, global info = 0.600, info = 0.600\n",
      "pattern:  ['B', 'C'] , local info = 0.400, global info = 0.400, info = 0.400\n",
      "pattern:  ['B', 'C', 'D'] , local info = 0.600, global info = 0.600, info = 0.600\n",
      "pattern:  ['B', 'C', 'E'] , local info = 0.600, global info = 0.600, info = 0.600\n",
      "pattern:  ['B', 'D'] , local info = 0.400, global info = 0.400, info = 0.400\n",
      "pattern:  ['B', 'E'] , local info = 0.400, global info = 0.400, info = 0.400\n",
      "pattern:  ['C', 'D'] , local info = 0.400, global info = 0.400, info = 0.400\n",
      "-> pattern:  ['A', 'B', 'C', 'D']  is sampled!\n",
      "--------------------------------------------------------------------------------\n",
      "pattern:  ['A', 'B'] , local info = 0.800, global info = 0.800, info = 0.800\n",
      "pattern:  ['A', 'B', 'C'] , local info = 0.800, global info = 0.800, info = 0.800\n",
      "pattern:  ['A', 'B', 'D'] , local info = 0.800, global info = 0.800, info = 0.800\n",
      "pattern:  ['A', 'C', 'D'] , local info = 0.800, global info = 0.800, info = 0.800\n",
      "pattern:  ['B', 'C'] , local info = 0.800, global info = 0.800, info = 0.800\n",
      "pattern:  ['B', 'C', 'D'] , local info = 0.800, global info = 0.800, info = 0.800\n",
      "pattern:  ['B', 'C', 'E'] , local info = 1.000, global info = 1.000, info = 1.000\n",
      "pattern:  ['B', 'D'] , local info = 0.800, global info = 0.800, info = 0.800\n",
      "pattern:  ['B', 'E'] , local info = 1.000, global info = 1.000, info = 1.000\n",
      "pattern:  ['C', 'D'] , local info = 0.800, global info = 0.800, info = 0.800\n",
      "-> pattern:  ['B', 'C', 'E']  is sampled!\n",
      "--------------------------------------------------------------------------------\n",
      "* Sample #1:  [['A', 'B', 'C', 'D'], ['B', 'C', 'E']]\n"
     ]
    }
   ],
   "source": [
    "sampled_patterns = sample(candidate_patterns)\n",
    "print(\"* Sample #1: \", sampled_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45b9175",
   "metadata": {},
   "source": [
    "### Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5c136",
   "metadata": {},
   "source": [
    "After we determined the sample, interactions are executed, collecting your favourites in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f80332e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you like the co-location pattern: [A, B, C, D]? (Y/n)\n",
      "y\n",
      "['A', 'B', 'C', 'D']  is your favourite.\n",
      "Do you like the co-location pattern: [B, C, E]? (Y/n)\n",
      "n\n"
     ]
    }
   ],
   "source": [
    "def interact(sampled_patterns, verbose=True):\n",
    "    preferred_patterns = []\n",
    "    for pattern in sampled_patterns:\n",
    "        feedback = input(\"Do you like the co-location pattern: [\"+ ', '.join(pattern) +\"]? (Y/n)\\n\")\n",
    "        if feedback.lower() == 'n':\n",
    "            continue\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(pattern, \" is your favourite.\")\n",
    "            preferred_patterns.append(pattern)\n",
    "    return preferred_patterns\n",
    "\n",
    "preferred_patterns = interact(sampled_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fbc299",
   "metadata": {},
   "source": [
    "# Step 3: Preference selection (Section IV. C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d24386",
   "metadata": {},
   "source": [
    "Define the pattern semantic distance (Def.14)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "010d2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_dist_operator(pattern1_embedding, pattern2_embedding):\n",
    "    pattern1_embedding_tiled = pattern1_embedding[: , np.newaxis, :]\n",
    "    pattern1_embedding_tiled = np.repeat(pattern1_embedding_tiled, pattern2_embedding.shape[0], axis=1)\n",
    "    pattern1_embedding_minus = pattern1_embedding_tiled - pattern2_embedding\n",
    "    distances = np.sqrt((pattern1_embedding_minus * pattern1_embedding_minus).sum(axis=-1))\n",
    "    min_distances = np.min(distances, axis=-1)\n",
    "\n",
    "    return np.sum(min_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aab9c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_semantic_dist(pattern1, pattern2):\n",
    "    pattern1_embedding = np.array(list(map(lambda f : EM[feature_index[f]], pattern1)))\n",
    "    pattern2_embedding = np.array(list(map(lambda f : EM[feature_index[f]], pattern2)))\n",
    "    \n",
    "    distance1 = min_dist_operator(pattern1_embedding, pattern2_embedding)\n",
    "    distance2 = min_dist_operator(pattern2_embedding, pattern1_embedding)\n",
    "    \n",
    "    return (distance1 + distance2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ffe4d8",
   "metadata": {},
   "source": [
    "Define the pattern structural distance (Def.13)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc30fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_structural_dist(pattern1, pattern2, adjusting_factor=1e-6):\n",
    "    pattern1_set = set(pattern1)\n",
    "    pattern2_set = set(pattern2)\n",
    "    \n",
    "    intersection = pattern1_set.intersection(pattern2)\n",
    "    union = pattern1_set.union(pattern2)\n",
    "    \n",
    "    return 1 - len(intersection) / len(union) + adjusting_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccb1270",
   "metadata": {},
   "source": [
    "Define the final pattern distance (Def.15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce78d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pattern_distance(pattern1, pattern2, structural_influence_index=1.0):\n",
    "    semantic_distance = calc_semantic_dist(pattern1, pattern2)\n",
    "    structural_distance = calc_structural_dist(pattern1, pattern2, 0)\n",
    "    \n",
    "    return semantic_distance / math.pow(structural_distance, structural_influence_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949a8e07",
   "metadata": {},
   "source": [
    "Let's recall what we have selected as preferences before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9015ae21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'B', 'C', 'D']]\n"
     ]
    }
   ],
   "source": [
    "print(preferred_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb417e2",
   "metadata": {},
   "source": [
    "For each preferred co-location patterns, we choose the top-2 nearest patterns as deduced preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ffd488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the co-location pattern  ['A', 'B', 'C', 'D'] , we choose these patterns as your preferences:\n",
      "1. ['A', 'B', 'C']\n",
      "2. ['A', 'C', 'D']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def select_preference(preferred_patterns, candidate_patterns, \n",
    "                      nearest_pattern_size=2, structural_influence_index=1.0, verbose=True):\n",
    "    selected_preferences = []\n",
    "    for preferred_pattern in preferred_patterns:\n",
    "        pattern_dist_pairs = []\n",
    "        for candidate_pattern in candidate_patterns:\n",
    "            distance = calc_pattern_distance(preferred_pattern, candidate_pattern)\n",
    "            pattern_dist_pairs.append([distance, candidate_pattern])\n",
    "\n",
    "        pattern_dist_pairs = sorted(pattern_dist_pairs)\n",
    "\n",
    "        # Select the top-k nearest patterns.\n",
    "        top_nearest_patterns = pattern_dist_pairs[: nearest_pattern_size]\n",
    "\n",
    "        if verbose:\n",
    "            print('For the co-location pattern ', preferred_pattern, \", we choose these patterns as your preferences:\")\n",
    "        for idx, top_nearest_pattern in enumerate(top_nearest_patterns):\n",
    "            if verbose:\n",
    "                print('%d. %s' % (idx + 1, top_nearest_pattern[1]))\n",
    "            selected_preferences.append(top_nearest_pattern[1])\n",
    "            candidate_patterns.remove(top_nearest_pattern[1])\n",
    "        if verbose:\n",
    "            print('-'*80)\n",
    "    return selected_preferences\n",
    "        \n",
    "# The variable ns.\n",
    "nearest_pattern_size = 2\n",
    "# The variable w in the paper.\n",
    "structural_influence_index = 1.0\n",
    "\n",
    "selected_preferences = select_preference(preferred_patterns, candidate_patterns, nearest_pattern_size, structural_influence_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3943909",
   "metadata": {},
   "source": [
    "Our recommendations for this round are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59bbbb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'B', 'C'], ['A', 'C', 'D']]\n"
     ]
    }
   ],
   "source": [
    "print(selected_preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e084ebe",
   "metadata": {},
   "source": [
    "# Further steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55115817",
   "metadata": {},
   "source": [
    "After providing our recommendations, the round is over. Next, the algorithm, FITTER, iteratively executes Steps 2 and 3, until the vairable $candidate\\_patterns$ is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43047023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you like the co-location pattern: [A, B, D]? (Y/n)\n",
      "y\n",
      "Do you like the co-location pattern: [B, C]? (Y/n)\n",
      "y\n",
      "Do you like the co-location pattern: [B, D]? (Y/n)\n",
      "n\n"
     ]
    }
   ],
   "source": [
    "while len(candidate_patterns) != 0:\n",
    "    sampled_patterns = sample(candidate_patterns, verbose=False)\n",
    "    preferred_patterns = interact(sampled_patterns, verbose=False)\n",
    "    round_preferences = select_preference(preferred_patterns, candidate_patterns, verbose=False)\n",
    "    if len(round_preferences) != 0:\n",
    "        selected_preferences.extend(round_preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b8c649",
   "metadata": {},
   "source": [
    "The final results are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cbdf175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'B', 'C'], ['A', 'C', 'D'], ['A', 'B'], ['C', 'D'], ['B', 'E'], ['B', 'C', 'D']]\n"
     ]
    }
   ],
   "source": [
    "print(selected_preferences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
